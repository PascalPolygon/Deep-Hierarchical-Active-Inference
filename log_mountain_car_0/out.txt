04:18:52

=== Loading experiment [device: cpu] ===

{'action_noise': None,
 'action_noise_scale': 0.1,
 'action_repeat': 3,
 'batch_size': 50,
 'context_length': 7,
 'coverage': False,
 'ensemble_size': 25,
 'env_name': 'SparseMountainCar',
 'epsilon': 1e-08,
 'expl_scale': 1.0,
 'expl_strategy': 'information',
 'grad_clip_norm': 1000,
 'hidden_size': 200,
 'learning_rate': 0.001,
 'logdir': 'mountain_car',
 'max_episode_len': 500,
 'n_candidates': 500,
 'n_episodes': 50,
 'n_seed_episodes': 1,
 'n_train_epochs': 100,
 'optimisation_iters': 5,
 'plan_horizon': 30,
 'record_every': None,
 'reward_scale': 1.0,
 'seed': 0,
 'strategy': 'information',
 'top_candidates': 50,
 'use_exploration': True,
 'use_mean': False,
 'use_reward': True}
Low-level transition added: state=[-0.58912799  0.        ], goal=[-0.58304867  0.00302843], action=[0.354103], reward=0, next_state=[-0.58304867  0.00302843], next_goal=[-0.58304867  0.00302843]
Low-level transition added: state=[-0.58304867  0.00302843], goal=[-0.57399629  0.00298956], action=[-0.28936675], reward=0, next_state=[-0.57399629  0.00298956], next_goal=[-0.57399629  0.00298956]
Low-level transition added: state=[-0.57399629  0.00298956], goal=[-0.55924511  0.00584774], action=[0.40537468], reward=0, next_state=[-0.55924511  0.00584774], next_goal=[-0.55924511  0.00584774]
Low-level transition added: state=[-0.55924511  0.00584774], goal=[-0.54187999  0.00571518], action=[-0.17831482], reward=0, next_state=[-0.54187999  0.00571518], next_goal=[-0.54187999  0.00571518]
Low-level transition added: state=[-0.54187999  0.00571518], goal=[-0.51634694  0.00985016], action=[0.86555284], reward=0, next_state=[-0.51634694  0.00985016], next_goal=[-0.51634694  0.00985016]
Low-level transition added: state=[-0.51634694  0.00985016], goal=[-0.47891819  0.01370048], action=[0.95004386], reward=0, next_state=[-0.47891819  0.01370048], next_goal=[-0.47891819  0.01370048]
Low-level transition added: state=[-0.47891819  0.01370048], goal=[-0.44090741  0.0120593 ], action=[-0.0775544], reward=0, next_state=[-0.44090741  0.0120593 ], next_goal=[-0.44090741  0.0120593 ]
Low-level transition added: state=[-0.44090741  0.0120593 ], goal=[-0.40067963  0.01398991], action=[0.9007473], reward=0, next_state=[-0.40067963  0.01398991], next_goal=[-0.40067963  0.01398991]
Low-level transition added: state=[-0.40067963  0.01398991], goal=[-0.36848408  0.00902291], action=[-0.44834465], reward=0, next_state=[-0.36848408  0.00902291], next_goal=[-0.36848408  0.00902291]
Low-level transition added: state=[-0.36848408  0.00902291], goal=[-0.35305382  0.00316295], action=[-0.52569586], reward=0, next_state=[-0.35305382  0.00316295], next_goal=[-0.35305382  0.00316295]
Low-level transition added: state=[-0.35305382  0.00316295], goal=[-0.34839065  0.00073732], action=[0.28609675], reward=0, next_state=[-0.34839065  0.00073732], next_goal=[-0.34839065  0.00073732]
Low-level transition added: state=[-0.34839065  0.00073732], goal=[-0.35186021 -0.00209898], action=[0.20368332], reward=0, next_state=[-0.35186021 -0.00209898], next_goal=[-0.35186021 -0.00209898]
Low-level transition added: state=[-0.35186021 -0.00209898], goal=[-0.36855348 -0.00726614], action=[-0.3464356], reward=0, next_state=[-0.36855348 -0.00726614], next_goal=[-0.36855348 -0.00726614]
Low-level transition added: state=[-0.36855348 -0.00726614], goal=[-0.39352805 -0.00879936], action=[0.3707464], reward=0, next_state=[-0.39352805 -0.00879936], next_goal=[-0.39352805 -0.00879936]
Low-level transition added: state=[-0.39352805 -0.00879936], goal=[-0.42275723 -0.01014799], action=[0.29009968], reward=0, next_state=[-0.42275723 -0.01014799], next_goal=[-0.42275723 -0.01014799]
Low-level transition added: state=[-0.42275723 -0.01014799], goal=[-0.45996721 -0.01344505], action=[-0.29244804], reward=0, next_state=[-0.45996721 -0.01344505], next_goal=[-0.45996721 -0.01344505]
Low-level transition added: state=[-0.45996721 -0.01344505], goal=[-0.49574164 -0.01107317], action=[0.7817098], reward=0, next_state=[-0.49574164 -0.01107317], next_goal=[-0.49574164 -0.01107317]
Low-level transition added: state=[-0.49574164 -0.01107317], goal=[-0.53087796 -0.01194473], action=[-0.11219462], reward=0, next_state=[-0.53087796 -0.01194473], next_goal=[-0.53087796 -0.01194473]
Low-level transition added: state=[-0.53087796 -0.01194473], goal=[-0.56665717 -0.01182759], action=[-0.07018214], reward=0, next_state=[-0.56665717 -0.01182759], next_goal=[-0.56665717 -0.01182759]
Low-level transition added: state=[-0.56665717 -0.01182759], goal=[-0.594686   -0.00802657], action=[0.57952666], reward=0, next_state=[-0.594686   -0.00802657], next_goal=[-0.594686   -0.00802657]
Low-level transition added: state=[-0.594686   -0.00802657], goal=[-0.62322843 -0.01019111], action=[-0.87777114], reward=0, next_state=[-0.62322843 -0.01019111], next_goal=[-0.62322843 -0.01019111]
Low-level transition added: state=[-0.62322843 -0.01019111], goal=[-0.65021716 -0.00833256], action=[-0.12247797], reward=0, next_state=[-0.65021716 -0.00833256], next_goal=[-0.65021716 -0.00833256]
Low-level transition added: state=[-0.65021716 -0.00833256], goal=[-0.66748005 -0.0044208 ], action=[0.22068031], reward=0, next_state=[-0.66748005 -0.0044208 ], next_goal=[-0.66748005 -0.0044208 ]
Low-level transition added: state=[-0.66748005 -0.0044208 ], goal=[-0.67443917 -0.00124979], action=[-0.00632538], reward=0, next_state=[-0.67443917 -0.00124979], next_goal=[-0.67443917 -0.00124979]
Low-level transition added: state=[-0.67443917 -0.00124979], goal=[-6.75197019e-01  2.49367265e-04], action=[-0.39821568], reward=0, next_state=[-6.75197019e-01  2.49367265e-04], next_goal=[-6.75197019e-01  2.49367265e-04]
Low-level transition added: state=[-6.75197019e-01  2.49367265e-04], goal=[-0.66396326  0.00547271], action=[0.440285], reward=0, next_state=[-0.66396326  0.00547271], next_goal=[-0.66396326  0.00547271]
Low-level transition added: state=[-0.66396326  0.00547271], goal=[-0.64199643  0.00819952], action=[-0.04435827], reward=0, next_state=[-0.64199643  0.00819952], next_goal=[-0.64199643  0.00819952]
Low-level transition added: state=[-0.64199643  0.00819952], goal=[-0.60391914  0.01485625], action=[0.95287883], reward=0, next_state=[-0.60391914  0.01485625], next_goal=[-0.60391914  0.01485625]
Low-level transition added: state=[-0.60391914  0.01485625], goal=[-0.55999355  0.01442621], action=[-0.42097774], reward=0, next_state=[-0.55999355  0.01442621], next_goal=[-0.55999355  0.01442621]
Low-level transition added: state=[-0.55999355  0.01442621], goal=[-0.51198174  0.01667556], action=[0.39573857], reward=0, next_state=[-0.51198174  0.01667556], next_goal=[-0.51198174  0.01667556]
Low-level transition added: state=[-0.51198174  0.01667556], goal=[-0.4589954   0.01802485], action=[0.4446395], reward=0, next_state=[-0.4589954   0.01802485], next_goal=[-0.4589954   0.01802485]
Low-level transition added: state=[-0.4589954   0.01802485], goal=[-0.41374758  0.01349591], action=[-0.6070088], reward=0, next_state=[-0.41374758  0.01349591], next_goal=[-0.41374758  0.01349591]
Low-level transition added: state=[-0.41374758  0.01349591], goal=[-0.38592572  0.00709025], action=[-0.83386374], reward=0, next_state=[-0.38592572  0.00709025], next_goal=[-0.38592572  0.00709025]
Low-level transition added: state=[-0.38592572  0.00709025], goal=[-0.36478699  0.00697606], action=[0.6757864], reward=0, next_state=[-0.36478699  0.00697606], next_goal=[-0.36478699  0.00697606]
Low-level transition added: state=[-0.36478699  0.00697606], goal=[-0.34781778  0.00495693], action=[0.34263018], reward=0, next_state=[-0.34781778  0.00495693], next_goal=[-0.34781778  0.00495693]
Low-level transition added: state=[-0.34781778  0.00495693], goal=[-3.42602868e-01  1.12534646e-04], action=[-0.22565846], reward=0, next_state=[-3.42602868e-01  1.12534646e-04], next_goal=[-3.42602868e-01  1.12534646e-04]
Low-level transition added: state=[-3.42602868e-01  1.12534646e-04], goal=[-3.42035592e-01  2.26276374e-04], action=[0.887139], reward=0, next_state=[-3.42035592e-01  2.26276374e-04], next_goal=[-3.42035592e-01  2.26276374e-04]
Low-level transition added: state=[-3.42035592e-01  2.26276374e-04], goal=[-0.34486516 -0.00152373], action=[0.47231916], reward=0, next_state=[-0.34486516 -0.00152373], next_goal=[-0.34486516 -0.00152373]
Low-level transition added: state=[-0.34486516 -0.00152373], goal=[-0.36080558 -0.00717988], action=[-0.42305198], reward=0, next_state=[-0.36080558 -0.00717988], next_goal=[-0.36080558 -0.00717988]
Low-level transition added: state=[-0.36080558 -0.00717988], goal=[-0.38726542 -0.00958336], action=[0.21082073], reward=0, next_state=[-0.38726542 -0.00958336], next_goal=[-0.38726542 -0.00958336]
Low-level transition added: state=[-0.38726542 -0.00958336], goal=[-0.42711847 -0.0150482 ], action=[-0.60779476], reward=0, next_state=[-0.42711847 -0.0150482 ], next_goal=[-0.42711847 -0.0150482 ]
Low-level transition added: state=[-0.42711847 -0.0150482 ], goal=[-0.47721962 -0.01740744], action=[-0.12713613], reward=0, next_state=[-0.47721962 -0.01740744], next_goal=[-0.47721962 -0.01740744]
Low-level transition added: state=[-0.47721962 -0.01740744], goal=[-0.53150241 -0.0183033 ], action=[-0.05719303], reward=0, next_state=[-0.53150241 -0.0183033 ], next_goal=[-0.53150241 -0.0183033 ]
Low-level transition added: state=[-0.53150241 -0.0183033 ], goal=[-0.59105301 -0.02047771], action=[-0.6194863], reward=0, next_state=[-0.59105301 -0.02047771], next_goal=[-0.59105301 -0.02047771]
Low-level transition added: state=[-0.59105301 -0.02047771], goal=[-0.64096102 -0.01458705], action=[0.886877], reward=0, next_state=[-0.64096102 -0.01458705], next_goal=[-0.64096102 -0.01458705]
Low-level transition added: state=[-0.64096102 -0.01458705], goal=[-0.67854095 -0.01140573], action=[0.07074402], reward=0, next_state=[-0.67854095 -0.01140573], next_goal=[-0.67854095 -0.01140573]
Low-level transition added: state=[-0.67854095 -0.01140573], goal=[-0.70617658 -0.0080503 ], action=[-0.04549681], reward=0, next_state=[-0.70617658 -0.0080503 ], next_goal=[-0.70617658 -0.0080503 ]
Low-level transition added: state=[-0.70617658 -0.0080503 ], goal=[-7.14665513e-01 -1.92961859e-04], action=[0.85870963], reward=0, next_state=[-7.14665513e-01 -1.92961859e-04], next_goal=[-7.14665513e-01 -1.92961859e-04]
Low-level transition added: state=[-7.14665513e-01 -1.92961859e-04], goal=[-0.70227982  0.00626994], action=[0.5437186], reward=0, next_state=[-0.70227982  0.00626994], next_goal=[-0.70227982  0.00626994]
Low-level transition added: state=[-0.70227982  0.00626994], goal=[-0.67255226  0.01166968], action=[0.38671836], reward=0, next_state=[-0.67255226  0.01166968], next_goal=[-0.67255226  0.01166968]
Low-level transition added: state=[-0.67255226  0.01166968], goal=[-0.62407746  0.01829844], action=[0.8203234], reward=0, next_state=[-0.62407746  0.01829844], next_goal=[-0.62407746  0.01829844]
Low-level transition added: state=[-0.62407746  0.01829844], goal=[-0.56299957  0.02124478], action=[0.25551975], reward=0, next_state=[-0.56299957  0.02124478], next_goal=[-0.56299957  0.02124478]
Low-level transition added: state=[-0.56299957  0.02124478], goal=[-0.49906415  0.02118535], action=[-0.10315033], reward=0, next_state=[-0.49906415  0.02118535], next_goal=[-0.49906415  0.02118535]
Low-level transition added: state=[-0.49906415  0.02118535], goal=[-0.43273191  0.02241045], action=[0.5032959], reward=0, next_state=[-0.43273191  0.02241045], next_goal=[-0.43273191  0.02241045]
Low-level transition added: state=[-0.43273191  0.02241045], goal=[-0.37790937  0.01606867], action=[-0.8670009], reward=0, next_state=[-0.37790937  0.01606867], next_goal=[-0.37790937  0.01606867]
Low-level transition added: state=[-0.37790937  0.01606867], goal=[-0.34304953  0.00931042], action=[-0.7377212], reward=0, next_state=[-0.34304953  0.00931042], next_goal=[-0.34304953  0.00931042]
Low-level transition added: state=[-0.34304953  0.00931042], goal=[-0.31509085  0.00926511], action=[0.88865465], reward=0, next_state=[-0.31509085  0.00926511], next_goal=[-0.31509085  0.00926511]
Low-level transition added: state=[-0.31509085  0.00926511], goal=[-0.29301462  0.00635861], action=[0.36201856], reward=0, next_state=[-0.29301462  0.00635861], next_goal=[-0.29301462  0.00635861]
Low-level transition added: state=[-0.29301462  0.00635861], goal=[-0.29049279 -0.00193118], action=[-0.7687314], reward=0, next_state=[-0.29049279 -0.00193118], next_goal=[-0.29049279 -0.00193118]
Low-level transition added: state=[-0.29049279 -0.00193118], goal=[-0.30561572 -0.00657107], action=[0.02623038], reward=0, next_state=[-0.30561572 -0.00657107], next_goal=[-0.30561572 -0.00657107]
Low-level transition added: state=[-0.30561572 -0.00657107], goal=[-0.33305016 -0.01037995], action=[0.13393342], reward=0, next_state=[-0.33305016 -0.01037995], next_goal=[-0.33305016 -0.01037995]
Low-level transition added: state=[-0.33305016 -0.01037995], goal=[-0.37804325 -0.01721673], action=[-0.675601], reward=0, next_state=[-0.37804325 -0.01721673], next_goal=[-0.37804325 -0.01721673]
Low-level transition added: state=[-0.37804325 -0.01721673], goal=[-0.43492208 -0.0197017 ], action=[0.06738015], reward=0, next_state=[-0.43492208 -0.0197017 ], next_goal=[-0.43492208 -0.0197017 ]
Low-level transition added: state=[-0.43492208 -0.0197017 ], goal=[-0.49885794 -0.02196302], action=[-0.16621286], reward=0, next_state=[-0.49885794 -0.02196302], next_goal=[-0.49885794 -0.02196302]
Low-level transition added: state=[-0.49885794 -0.02196302], goal=[-0.57272673 -0.02577268], action=[-0.8420734], reward=0, next_state=[-0.57272673 -0.02577268], next_goal=[-0.57272673 -0.02577268]
Low-level transition added: state=[-0.57272673 -0.02577268], goal=[-0.65572315 -0.02841276], action=[-0.963883], reward=0, next_state=[-0.65572315 -0.02841276], next_goal=[-0.65572315 -0.02841276]
Low-level transition added: state=[-0.65572315 -0.02841276], goal=[-0.73694253 -0.02622047], action=[-0.27959034], reward=0, next_state=[-0.73694253 -0.02622047], next_goal=[-0.73694253 -0.02622047]
Low-level transition added: state=[-0.73694253 -0.02622047], goal=[-0.80031829 -0.01844969], action=[0.6437102], reward=0, next_state=[-0.80031829 -0.01844969], next_goal=[-0.80031829 -0.01844969]
Low-level transition added: state=[-0.80031829 -0.01844969], goal=[-0.84925406 -0.01516246], action=[-0.5544194], reward=0, next_state=[-0.84925406 -0.01516246], next_goal=[-0.84925406 -0.01516246]
Low-level transition added: state=[-0.84925406 -0.01516246], goal=[-0.8834858  -0.00948562], action=[-0.15365925], reward=0, next_state=[-0.8834858  -0.00948562], next_goal=[-0.8834858  -0.00948562]
Low-level transition added: state=[-0.8834858  -0.00948562], goal=[-0.89893665 -0.00296131], action=[-0.03493329], reward=0, next_state=[-0.89893665 -0.00296131], next_goal=[-0.89893665 -0.00296131]
Low-level transition added: state=[-0.89893665 -0.00296131], goal=[-0.89185258  0.00501934], action=[0.27024546], reward=0, next_state=[-0.89185258  0.00501934], next_goal=[-0.89185258  0.00501934]
Low-level transition added: state=[-0.89185258  0.00501934], goal=[-0.86213122  0.01232018], action=[0.15291226], reward=0, next_state=[-0.86213122  0.01232018], next_goal=[-0.86213122  0.01232018]
Low-level transition added: state=[-0.86213122  0.01232018], goal=[-0.81077144  0.01945196], action=[0.2120915], reward=0, next_state=[-0.81077144  0.01945196], next_goal=[-0.81077144  0.01945196]
Low-level transition added: state=[-0.81077144  0.01945196], goal=[-0.74003444  0.02552372], action=[0.1616647], reward=0, next_state=[-0.74003444  0.02552372], next_goal=[-0.74003444  0.02552372]
Low-level transition added: state=[-0.74003444  0.02552372], goal=[-0.66249176  0.02584662], action=[-0.8283743], reward=0, next_state=[-0.66249176  0.02584662], next_goal=[-0.66249176  0.02584662]
Low-level transition added: state=[-0.66249176  0.02584662], goal=[-0.57449775  0.03087136], action=[0.5749691], reward=0, next_state=[-0.57449775  0.03087136], next_goal=[-0.57449775  0.03087136]
Low-level transition added: state=[-0.57449775  0.03087136], goal=[-0.474052    0.03454081], action=[0.7250166], reward=0, next_state=[-0.474052    0.03454081], next_goal=[-0.474052    0.03454081]
Low-level transition added: state=[-0.474052    0.03454081], goal=[-0.37571634  0.03165547], action=[-0.23159815], reward=0, next_state=[-0.37571634  0.03165547], next_goal=[-0.37571634  0.03165547]
Low-level transition added: state=[-0.37571634  0.03165547], goal=[-0.2931067   0.02529182], action=[-0.57267255], reward=0, next_state=[-0.2931067   0.02529182], next_goal=[-0.2931067   0.02529182]
Low-level transition added: state=[-0.2931067   0.02529182], goal=[-0.22403765  0.02176043], action=[0.3651722], reward=0, next_state=[-0.22403765  0.02176043], next_goal=[-0.22403765  0.02176043]
Low-level transition added: state=[-0.22403765  0.02176043], goal=[-0.16523718  0.01843316], action=[0.62405974], reward=0, next_state=[-0.16523718  0.01843316], next_goal=[-0.16523718  0.01843316]
Low-level transition added: state=[-0.16523718  0.01843316], goal=[-0.12942973  0.00864239], action=[-0.6782377], reward=0, next_state=[-0.12942973  0.00864239], next_goal=[-0.12942973  0.00864239]
Low-level transition added: state=[-0.12942973  0.00864239], goal=[-0.1102825   0.00523368], action=[0.79805344], reward=0, next_state=[-0.1102825   0.00523368], next_goal=[-0.1102825   0.00523368]
Low-level transition added: state=[-0.1102825   0.00523368], goal=[-0.10567391 -0.00031842], action=[0.34689668], reward=0, next_state=[-0.10567391 -0.00031842], next_goal=[-0.10567391 -0.00031842]
Low-level transition added: state=[-0.10567391 -0.00031842], goal=[-0.11784331 -0.00591797], action=[0.33477724], reward=0, next_state=[-0.11784331 -0.00591797], next_goal=[-0.11784331 -0.00591797]
Low-level transition added: state=[-0.11784331 -0.00591797], goal=[-0.14444215 -0.01031791], action=[0.5714166], reward=0, next_state=[-0.14444215 -0.01031791], next_goal=[-0.14444215 -0.01031791]
Low-level transition added: state=[-0.14444215 -0.01031791], goal=[-0.18759387 -0.01637112], action=[0.13810721], reward=0, next_state=[-0.18759387 -0.01637112], next_goal=[-0.18759387 -0.01637112]
Low-level transition added: state=[-0.18759387 -0.01637112], goal=[-0.24947835 -0.02267109], action=[-0.04562408], reward=0, next_state=[-0.24947835 -0.02267109], next_goal=[-0.24947835 -0.02267109]
Low-level transition added: state=[-0.24947835 -0.02267109], goal=[-0.3256316  -0.02660501], action=[0.2581844], reward=0, next_state=[-0.3256316  -0.02660501], next_goal=[-0.3256316  -0.02660501]
Low-level transition added: state=[-0.3256316  -0.02660501], goal=[-0.41458214 -0.03098296], action=[-0.16466127], reward=0, next_state=[-0.41458214 -0.03098296], next_goal=[-0.41458214 -0.03098296]
Low-level transition added: state=[-0.41458214 -0.03098296], goal=[-0.50588869 -0.0299383 ], action=[0.6188374], reward=0, next_state=[-0.50588869 -0.0299383 ], next_goal=[-0.50588869 -0.0299383 ]
Low-level transition added: state=[-0.50588869 -0.0299383 ], goal=[-0.6017993  -0.03274986], action=[-0.69313294], reward=0, next_state=[-0.6017993  -0.03274986], next_goal=[-0.6017993  -0.03274986]
Low-level transition added: state=[-0.6017993  -0.03274986], goal=[-0.69166051 -0.02833749], action=[0.44571987], reward=0, next_state=[-0.69166051 -0.02833749], next_goal=[-0.69166051 -0.02833749]
Low-level transition added: state=[-0.69166051 -0.02833749], goal=[-0.77072307 -0.0251943 ], action=[-0.22055852], reward=0, next_state=[-0.77072307 -0.0251943 ], next_goal=[-0.77072307 -0.0251943 ]
Low-level transition added: state=[-0.77072307 -0.0251943 ], goal=[-0.83377052 -0.01881201], action=[0.21429874], reward=0, next_state=[-0.83377052 -0.01881201], next_goal=[-0.83377052 -0.01881201]
Low-level transition added: state=[-0.83377052 -0.01881201], goal=[-0.88619559 -0.01673247], action=[-0.92478937], reward=0, next_state=[-0.88619559 -0.01673247], next_goal=[-0.88619559 -0.01673247]
Low-level transition added: state=[-0.88619559 -0.01673247], goal=[-0.92648888 -0.01173479], action=[-0.3968746], reward=0, next_state=[-0.92648888 -0.01173479], next_goal=[-0.92648888 -0.01173479]
Low-level transition added: state=[-0.92648888 -0.01173479], goal=[-0.94739854 -0.00456714], action=[0.01988966], reward=0, next_state=[-0.94739854 -0.00456714], next_goal=[-0.94739854 -0.00456714]
Low-level transition added: state=[-0.94739854 -0.00456714], goal=[-0.94574417  0.00311235], action=[0.1123395], reward=0, next_state=[-0.94574417  0.00311235], next_goal=[-0.94574417  0.00311235]
Low-level transition added: state=[-0.94574417  0.00311235], goal=[-0.92624329  0.00818086], action=[-0.45531243], reward=0, next_state=[-0.92624329  0.00818086], next_goal=[-0.92624329  0.00818086]
Low-level transition added: state=[-0.92624329  0.00818086], goal=[-0.89327657  0.01236329], action=[-0.60964173], reward=0, next_state=[-0.89327657  0.01236329], next_goal=[-0.89327657  0.01236329]
Low-level transition added: state=[-0.89327657  0.01236329], goal=[-0.84357884  0.01861049], action=[-0.06740179], reward=0, next_state=[-0.84357884  0.01861049], next_goal=[-0.84357884  0.01861049]
Low-level transition added: state=[-0.84357884  0.01861049], goal=[-0.76885916  0.02794425], action=[0.7797759], reward=0, next_state=[-0.76885916  0.02794425], next_goal=[-0.76885916  0.02794425]
Low-level transition added: state=[-0.76885916  0.02794425], goal=[-0.67251556  0.03401278], action=[0.35173687], reward=0, next_state=[-0.67251556  0.03401278], next_goal=[-0.67251556  0.03401278]
Low-level transition added: state=[-0.67251556  0.03401278], goal=[-0.56637254  0.03581707], action=[-0.1552495], reward=0, next_state=[-0.56637254  0.03581707], next_goal=[-0.56637254  0.03581707]
Low-level transition added: state=[-0.56637254  0.03581707], goal=[-0.45672609  0.03664152], action=[0.15175249], reward=0, next_state=[-0.45672609  0.03664152], next_goal=[-0.45672609  0.03664152]
Low-level transition added: state=[-0.45672609  0.03664152], goal=[-0.35688217  0.03135653], action=[-0.67692226], reward=0, next_state=[-0.35688217  0.03135653], next_goal=[-0.35688217  0.03135653]
Low-level transition added: state=[-0.35688217  0.03135653], goal=[-0.27038056  0.02738844], action=[0.04233043], reward=0, next_state=[-0.27038056  0.02738844], next_goal=[-0.27038056  0.02738844]
Low-level transition added: state=[-0.27038056  0.02738844], goal=[-0.20600393  0.01837761], action=[-0.77429396], reward=0, next_state=[-0.20600393  0.01837761], next_goal=[-0.20600393  0.01837761]
Low-level transition added: state=[-0.20600393  0.01837761], goal=[-0.16185519  0.01282209], action=[0.16749263], reward=0, next_state=[-0.16185519  0.01282209], next_goal=[-0.16185519  0.01282209]
Low-level transition added: state=[-0.16185519  0.01282209], goal=[-0.13767707  0.00564731], action=[-0.09883499], reward=0, next_state=[-0.13767707  0.00564731], next_goal=[-0.13767707  0.00564731]
Low-level transition added: state=[-0.13767707  0.00564731], goal=[-0.14216429 -0.00506814], action=[-0.85292864], reward=0, next_state=[-0.14216429 -0.00506814], next_goal=[-0.14216429 -0.00506814]
Low-level transition added: state=[-0.14216429 -0.00506814], goal=[-0.17924566 -0.01597161], action=[-0.92737764], reward=0, next_state=[-0.17924566 -0.01597161], next_goal=[-0.17924566 -0.01597161]
Low-level transition added: state=[-0.17924566 -0.01597161], goal=[-0.23634046 -0.02048495], action=[0.378784], reward=0, next_state=[-0.23634046 -0.02048495], next_goal=[-0.23634046 -0.02048495]
Low-level transition added: state=[-0.23634046 -0.02048495], goal=[-0.3003043  -0.02162871], action=[0.93803644], reward=0, next_state=[-0.3003043  -0.02162871], next_goal=[-0.3003043  -0.02162871]
Low-level transition added: state=[-0.3003043  -0.02162871], goal=[-0.3679102  -0.02285044], action=[0.6722172], reward=0, next_state=[-0.3679102  -0.02285044], next_goal=[-0.3679102  -0.02285044]
Low-level transition added: state=[-0.3679102  -0.02285044], goal=[-0.44137676 -0.02514091], action=[0.1311719], reward=0, next_state=[-0.44137676 -0.02514091], next_goal=[-0.44137676 -0.02514091]
Low-level transition added: state=[-0.44137676 -0.02514091], goal=[-0.52547601 -0.02927658], action=[-0.64569646], reward=0, next_state=[-0.52547601 -0.02927658], next_goal=[-0.52547601 -0.02927658]
Low-level transition added: state=[-0.52547601 -0.02927658], goal=[-0.6071689  -0.02600038], action=[0.57906127], reward=0, next_state=[-0.6071689  -0.02600038], next_goal=[-0.6071689  -0.02600038]
Low-level transition added: state=[-0.6071689  -0.02600038], goal=[-0.67970549 -0.02309255], action=[0.11440442], reward=0, next_state=[-0.67970549 -0.02309255], next_goal=[-0.67970549 -0.02309255]
Low-level transition added: state=[-0.67970549 -0.02309255], goal=[-0.73572938 -0.01633718], action=[0.66109824], reward=0, next_state=[-0.73572938 -0.01633718], next_goal=[-0.73572938 -0.01633718]
Low-level transition added: state=[-0.73572938 -0.01633718], goal=[-0.77603373 -0.01190072], action=[-0.06113473], reward=0, next_state=[-0.77603373 -0.01190072], next_goal=[-0.77603373 -0.01190072]
Low-level transition added: state=[-0.77603373 -0.01190072], goal=[-0.79300467 -0.00249649], action=[0.9171867], reward=0, next_state=[-0.79300467 -0.00249649], next_goal=[-0.79300467 -0.00249649]
Low-level transition added: state=[-0.79300467 -0.00249649], goal=[-7.94823048e-01  3.44644272e-04], action=[-0.57799995], reward=0, next_state=[-7.94823048e-01  3.44644272e-04], next_goal=[-7.94823048e-01  3.44644272e-04]
Low-level transition added: state=[-7.94823048e-01  3.44644272e-04], goal=[-0.78559448  0.00442951], action=[-0.29610327], reward=0, next_state=[-0.78559448  0.00442951], next_goal=[-0.78559448  0.00442951]
Low-level transition added: state=[-0.78559448  0.00442951], goal=[-0.76221557  0.00943699], action=[-0.04238078], reward=0, next_state=[-0.76221557  0.00943699], next_goal=[-0.76221557  0.00943699]
Low-level transition added: state=[-0.76221557  0.00943699], goal=[-0.72438207  0.01412917], action=[-0.00623493], reward=0, next_state=[-0.72438207  0.01412917], next_goal=[-0.72438207  0.01412917]
Low-level transition added: state=[-0.72438207  0.01412917], goal=[-0.68023813  0.01491446], action=[-0.70830995], reward=0, next_state=[-0.68023813  0.01491446], next_goal=[-0.68023813  0.01491446]
Low-level transition added: state=[-0.68023813  0.01491446], goal=[-0.63074496  0.01717882], action=[-0.17865242], reward=0, next_state=[-0.63074496  0.01717882], next_goal=[-0.63074496  0.01717882]
Low-level transition added: state=[-0.63074496  0.01717882], goal=[-0.58119292  0.01606568], action=[-0.69318575], reward=0, next_state=[-0.58119292  0.01606568], next_goal=[-0.58119292  0.01606568]
Low-level transition added: state=[-0.58119292  0.01606568], goal=[-0.53091514  0.01698219], action=[-0.00063233], reward=0, next_state=[-0.53091514  0.01698219], next_goal=[-0.53091514  0.01698219]
Low-level transition added: state=[-0.53091514  0.01698219], goal=[-0.47702483  0.01832081], action=[0.34938294], reward=0, next_state=[-0.47702483  0.01832081], next_goal=[-0.47702483  0.01832081]
Low-level transition added: state=[-0.47702483  0.01832081], goal=[-0.42163498  0.01839851], action=[0.3401997], reward=0, next_state=[-0.42163498  0.01839851], next_goal=[-0.42163498  0.01839851]
Low-level transition added: state=[-0.42163498  0.01839851], goal=[-0.3682287   0.01737749], action=[0.359825], reward=0, next_state=[-0.3682287   0.01737749], next_goal=[-0.3682287   0.01737749]
Low-level transition added: state=[-0.3682287   0.01737749], goal=[-0.32732896  0.01166547], action=[-0.45489886], reward=0, next_state=[-0.32732896  0.01166547], next_goal=[-0.32732896  0.01166547]
Low-level transition added: state=[-0.32732896  0.01166547], goal=[-0.30282525  0.00636361], action=[-0.21424176], reward=0, next_state=[-0.30282525  0.00636361], next_goal=[-0.30282525  0.00636361]
Low-level transition added: state=[-0.30282525  0.00636361], goal=[-0.29394207  0.00123738], action=[-0.0981743], reward=0, next_state=[-0.29394207  0.00123738], next_goal=[-0.29394207  0.00123738]
Low-level transition added: state=[-0.29394207  0.00123738], goal=[-0.3015326  -0.00440469], action=[-0.19917563], reward=0, next_state=[-0.3015326  -0.00440469], next_goal=[-0.3015326  -0.00440469]
Low-level transition added: state=[-0.3015326  -0.00440469], goal=[-0.31982897 -0.00691183], action=[0.45079467], reward=0, next_state=[-0.31982897 -0.00691183], next_goal=[-0.31982897 -0.00691183]
Low-level transition added: state=[-0.31982897 -0.00691183], goal=[-0.35682203 -0.01497147], action=[-0.8785157], reward=0, next_state=[-0.35682203 -0.01497147], next_goal=[-0.35682203 -0.01497147]
Low-level transition added: state=[-0.35682203 -0.01497147], goal=[-0.4170184 -0.0224848], action=[-0.9529349], reward=0, next_state=[-0.4170184 -0.0224848], next_goal=[-0.4170184 -0.0224848]
Low-level transition added: state=[-0.4170184 -0.0224848], goal=[-0.48422718 -0.02219867], action=[0.47880933], reward=0, next_state=[-0.48422718 -0.02219867], next_goal=[-0.48422718 -0.02219867]
Low-level transition added: state=[-0.48422718 -0.02219867], goal=[-0.56051044 -0.0268573 ], action=[-0.9608193], reward=0, next_state=[-0.56051044 -0.0268573 ], next_goal=[-0.56051044 -0.0268573 ]
Low-level transition added: state=[-0.56051044 -0.0268573 ], goal=[-0.63501848 -0.02363811], action=[0.4051754], reward=0, next_state=[-0.63501848 -0.02363811], next_goal=[-0.63501848 -0.02363811]
Low-level transition added: state=[-0.63501848 -0.02363811], goal=[-0.70500406 -0.02301195], action=[-0.51619625], reward=0, next_state=[-0.70500406 -0.02301195], next_goal=[-0.70500406 -0.02301195]
Low-level transition added: state=[-0.70500406 -0.02301195], goal=[-0.77254582 -0.02212565], action=[-0.75974005], reward=0, next_state=[-0.77254582 -0.02212565], next_goal=[-0.77254582 -0.02212565]
Low-level transition added: state=[-0.77254582 -0.02212565], goal=[-0.82914669 -0.0171352 ], action=[-0.09315235], reward=0, next_state=[-0.82914669 -0.0171352 ], next_goal=[-0.82914669 -0.0171352 ]
Low-level transition added: state=[-0.82914669 -0.0171352 ], goal=[-0.87439519 -0.01398979], action=[-0.6692035], reward=0, next_state=[-0.87439519 -0.01398979], next_goal=[-0.87439519 -0.01398979]
Low-level transition added: state=[-0.87439519 -0.01398979], goal=[-0.90773264 -0.00963257], action=[-0.5077936], reward=0, next_state=[-0.90773264 -0.00963257], next_goal=[-0.90773264 -0.00963257]
Low-level transition added: state=[-0.90773264 -0.00963257], goal=[-0.93048313 -0.00653561], action=[-0.85073704], reward=0, next_state=[-0.93048313 -0.00653561], next_goal=[-0.93048313 -0.00653561]
Low-level transition added: state=[-0.93048313 -0.00653561], goal=[-0.93994207 -0.0014517 ], action=[-0.44292685], reward=0, next_state=[-0.93994207 -0.0014517 ], next_goal=[-0.93994207 -0.0014517 ]
Low-level transition added: state=[-0.93994207 -0.0014517 ], goal=[-0.92732752  0.00702634], action=[0.30662975], reward=0, next_state=[-0.92732752  0.00702634], next_goal=[-0.92732752  0.00702634]
Low-level transition added: state=[-0.92732752  0.00702634], goal=[-0.8874744   0.01637954], action=[0.53968734], reward=0, next_state=[-0.8874744   0.01637954], next_goal=[-0.8874744   0.01637954]
Low-level transition added: state=[-0.8874744   0.01637954], goal=[-0.82644448  0.0222508 ], action=[-0.12628514], reward=0, next_state=[-0.82644448  0.0222508 ], next_goal=[-0.82644448  0.0222508 ]
Low-level transition added: state=[-0.82644448  0.0222508 ], goal=[-0.7483414   0.02779938], action=[0.00097181], reward=0, next_state=[-0.7483414   0.02779938], next_goal=[-0.7483414   0.02779938]
Low-level transition added: state=[-0.7483414   0.02779938], goal=[-0.66500207  0.02759655], action=[-0.9709846], reward=0, next_state=[-0.66500207  0.02759655], next_goal=[-0.66500207  0.02759655]
Low-level transition added: state=[-0.66500207  0.02759655], goal=[-0.58481706  0.02610346], action=[-0.8908404], reward=0, next_state=[-0.58481706  0.02610346], next_goal=[-0.58481706  0.02610346]
Low-level transition added: state=[-0.58481706  0.02610346], goal=[-0.50167038  0.02831729], action=[0.32300064], reward=0, next_state=[-0.50167038  0.02831729], next_goal=[-0.50167038  0.02831729]
Low-level transition added: state=[-0.50167038  0.02831729], goal=[-0.42697579  0.02299697], action=[-0.9432347], reward=0, next_state=[-0.42697579  0.02299697], next_goal=[-0.42697579  0.02299697]
Low-level transition added: state=[-0.42697579  0.02299697], goal=[-0.36583728  0.01892233], action=[-0.32868662], reward=0, next_state=[-0.36583728  0.01892233], next_goal=[-0.36583728  0.01892233]
Low-level transition added: state=[-0.36583728  0.01892233], goal=[-0.32210025  0.01230512], action=[-0.6407497], reward=0, next_state=[-0.32210025  0.01230512], next_goal=[-0.32210025  0.01230512]
Low-level transition added: state=[-0.32210025  0.01230512], goal=[-0.29126073  0.00920198], action=[0.30200642], reward=0, next_state=[-0.29126073  0.00920198], next_goal=[-0.29126073  0.00920198]
Low-level transition added: state=[-0.29126073  0.00920198], goal=[-0.27517091  0.00340805], action=[-0.19245836], reward=0, next_state=[-0.27517091  0.00340805], next_goal=[-0.27517091  0.00340805]
Low-level transition added: state=[-0.27517091  0.00340805], goal=[-2.71813325e-01 -3.45364242e-05], action=[0.37218997], reward=0, next_state=[-2.71813325e-01 -3.45364242e-05], next_goal=[-2.71813325e-01 -3.45364242e-05]
Low-level transition added: state=[-2.71813325e-01 -3.45364242e-05], goal=[-0.28351254 -0.00581615], action=[-0.15182403], reward=0, next_state=[-0.28351254 -0.00581615], next_goal=[-0.28351254 -0.00581615]
Low-level transition added: state=[-0.28351254 -0.00581615], goal=[-0.29859947 -0.00810599], action=[0.32277903], reward=0, next_state=[-0.29859947 -0.00810599], next_goal=[-0.29859947 -0.00810599]
Episode 1/1 complete.

Collected seeds: [1 episodes | 167 frames]

=== Episode 1 ===
Training on [167/501] data points
> High-Level Train epoch 20 [ensemble 3793.69 | reward 0.00]
> Low-Level Train epoch 20 [action 0.28]
> High-Level Train epoch 40 [ensemble 1929.27 | reward 0.00]
> Low-Level Train epoch 40 [action 0.27]
> High-Level Train epoch 60 [ensemble 1293.98 | reward 0.00]
> Low-Level Train epoch 60 [action 0.27]
> High-Level Train epoch 80 [ensemble 973.78 | reward 0.00]
> Low-Level Train epoch 80 [action 0.27]
> High-Level Train epoch 100 [ensemble 781.02 | reward 0.00]
> Low-Level Train epoch 100 [action 0.27]
Ensemble loss 781.02 / Reward Loss 0.00 / Action Loss 0.27

=== Collecting data [1] ===