10:38:13

=== Loading experiment [device: cpu] ===

{'action_noise': None,
 'action_noise_scale': 0.1,
 'action_repeat': 3,
 'batch_size': 50,
 'context_length': 7,
 'coverage': False,
 'ensemble_size': 5,
 'env_name': 'SparseMountainCar',
 'epsilon': 1e-08,
 'expl_scale': 1.0,
 'expl_strategy': 'information',
 'grad_clip_norm': 1000,
 'hidden_size': 200,
 'learning_rate': 0.001,
 'logdir': 'log',
 'max_episode_len': 5,
 'n_candidates': 500,
 'n_episodes': 5,
 'n_seed_episodes': 1,
 'n_train_epochs': 1,
 'optimisation_iters': 5,
 'plan_horizon': 30,
 'record_every': None,
 'reward_scale': 1.0,
 'seed': 0,
 'strategy': 'information',
 'top_candidates': 50,
 'use_exploration': True,
 'use_mean': False,
 'use_reward': True}
Low-level transition added: state=[-0.58912799  0.        ], goal=[-0.57938231  0.00485483], action=[0.7639891], reward=0, next_state=[-0.57938231  0.00485483], next_goal=[-0.57938231  0.00485483]
Low-level transition added: state=[-0.57938231  0.00485483], goal=[-0.57250652  0.00295591], action=[-0.9009176], reward=0, next_state=[-0.57250652  0.00295591], next_goal=[-0.57250652  0.00295591]
Episode 1/1 complete.

Collected seeds: [1 episodes | 2 frames]

=== Episode 1 ===
Training on [2/6] data points
Ensemble loss inf / Reward Loss inf / Action Loss 0.03

=== Collecting data [1] ===
Step 0: state=[-0.40692181  0.        ], goal=[ 0.46592334 -0.03680629], action=[-0.0161878], reward=0, next_state=[-0.41218036 -0.00261997], next_goal=[ 0.47118189 -0.03418633]